(window.webpackJsonp=window.webpackJsonp||[]).push([[66],{205:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return l})),n.d(t,"rightToc",(function(){return s})),n.d(t,"default",(function(){return p}));var a=n(1),i=n(9),r=(n(0),n(441)),o={},l={id:"jme3/advanced/pbr_part3",title:"pbr_part3",description:"![irradianceMap](/images/jme3/advanced/irradianceMap.png)",source:"@site/docs/jme3/advanced/pbr_part3.md",permalink:"/wikidemo/docs/jme3/advanced/pbr_part3",editUrl:"https://github.com/8keep/wikidemo/edit/master/docs/jme3/advanced/pbr_part3.md"},s=[{value:"Reminder on environment maps :",id:"reminder-on-environment-maps-",children:[]},{value:"IBL Diffuse",id:"ibl-diffuse",children:[]},{value:"IBL Specular",id:"ibl-specular",children:[]},{value:"Thanks Epic games!",id:"thanks-epic-games",children:[]}],c={rightToc:s};function p(e){var t=e.components,n=Object(i.a)(e,["components"]);return Object(r.b)("wrapper",Object(a.a)({},c,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/irradianceMap.png",alt:"irradianceMap"}))),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Note"),' : after several discussions in the team, I realized that some\npoints were not clear in the "PBR for artists" post. I\'ve made an update\nwith additional information on how to handle metalness and specular. I\ninvite you to read it.'),Object(r.b)("p",null,Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"../../jme3%5Cadvanced%5Cpbr_part1"}),"Physically Based Rendering -- Part\none")),Object(r.b)("h1",{id:"image-based-lighting-in-pbr"},"Image Based Lighting in PBR"),Object(r.b)("p",null,"In ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"../../jme3/advanced/pbr_part2"}),"Physically Based Rendering -- Part\nTwo"),", I talked about the basics of\nPBR for developers, and explained the different steps of the lighting\nprocess with PBR."),Object(r.b)("p",null,"As said before, PBR does not necessarily imply to have indirect\nlighting, But that's what makes it look so good."),Object(r.b)("p",null,"Today I'm gonna focus on a technique called Image Based Lighting (IBL),\nthat will allow us to cheaply compute this indirect lighting."),Object(r.b)("p",null,"As before you can find at the end of the article a lexical with\ndefinitions of various unusual terms you'll come across."),Object(r.b)("h1",{id:"indirect-lighting-for-pbr-with-image-based-lighting"},"Indirect Lighting for PBR with Image Based Lighting."),Object(r.b)("p",null,"Direct lighting is usually pretty clear for everyone as it uses common\nlight sources (point light, directional light,...)."),Object(r.b)("p",null,"However indirect lighting is not that obvious. First you need to\nunderstand what we want to simulate with indirect light."),Object(r.b)("p",null,"It is often referred as ",Object(r.b)("strong",{parentName:"p"},"Global Illumination (or GI)"),". This represents\nthe light bouncing on surrounding objects that is lighting the shaded\nsurface. There are several techniques to implement global illumination,\nbut the most common is ",Object(r.b)("strong",{parentName:"p"},"Image Based Lighting (IBL)"),". It is very often\nassociated with PBR pipelines."),Object(r.b)("p",null,"So basically, a light source in game is a color, and optionally other\nparameters like direction, position, radius, etc... An image has color\ninformations, and this color can be considered as a light source."),Object(r.b)("p",null,"For global Illumination light is coming from everywhere. So a good way\nto simulate GI with IBL is to consider an environment map as a light\nsource."),Object(r.b)("h2",{id:"reminder-on-environment-maps-"},"Reminder on environment maps :"),Object(r.b)("p",null,"Most often, in-game environment maps are cube maps."),Object(r.b)("p",null,"How do we fetch a pixel from an environment map? We need a vector. Often\ncalled the reflect vector (refVec), because thats the reflection vector\nof the view direction on the shaded surface."),Object(r.b)("p",null,"A picture worth thousand words"),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/Cube_mapped_reflection_example.jpg",alt:"Cube_mapped_reflection_example"}))),Object(r.b)("p",null,"from wikipedia : TopherTH at the English language Wikipedia ","[","GFDL\n(",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"http://www.gnu.org/copyleft/fdl.html"}),"http://www.gnu.org/copyleft/fdl.html"),"), GFDL\n(",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"http://www.gnu.org/copyleft/fdl.html"}),"http://www.gnu.org/copyleft/fdl.html"),") or CC-BY-SA-3.0\n(",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"http://creativecommons.org/licenses/by-sa/3.0/"}),"http://creativecommons.org/licenses/by-sa/3.0/"),")","]",", via Wikimedia\nCommons Here the reflected Ray is our reflection vector."),Object(r.b)("p",null,"Here the reflected Ray is our reflection vector."),Object(r.b)("p",null,"Unfortunately we can't take each pixel of the env map and compute light\nas if it was a direct light source and hope for the best."),Object(r.b)("p",null,"There's crazy math around that topic, and to be honest I didn't get all\nof it myself. So instead of explaining difficult math equations that may\nbe confusing, I'm gonna go straight to the point : How are we going to\ncompute lighting from the environment map?"),Object(r.b)("h2",{id:"ibl-diffuse"},"IBL Diffuse"),Object(r.b)("p",null,"First we need to compute Diffuse factor from the environment map.\nRemember our diffuse BRDF from last post? ",Object(r.b)("strong",{parentName:"p"},"Lambert"),"."),Object(r.b)("p",null,"To simplify, Lambert diffuse BRDF, as it's used in game, is the light\ncolor multiplied by a visibility factor."),Object(r.b)("p",null,"This visibility factor is a function of the normal of the shaded\ngeometry and the light direction."),Object(r.b)("p",null,"Let's say you have a direct light source lighting the front side of a\ngeometry. The back side of this geometry is in the dark. Meaning the\nfront side visibility factor is 1 and the back side visibility factor is\n0."),Object(r.b)("p",null,"For indirect lighting, we can ditch out this visibility factor because\nthe light is coming from everywhere. So all of this simplifies in\nDiffuse factor = light color."),Object(r.b)("p",null,"But what's the light color for a given point?"),Object(r.b)("p",null,"Technically, every pixel in the environment map is a light source, so a\nshaded point is lighten by a vast amount of pixels."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/irradiance.png",alt:"irradiance"}))),Object(r.b)("p",null,"In this picture the orange area represent the light rays coming from the\ncube map to the shaded pixel, that we have to consider to properly\ncompute the light color. So the idea would be, for each shaded pixel, to\nfetch all that texels and combine the colors."),Object(r.b)("p",null,"As you can image that's not practical for a real time rendering\npipeline. Even with a 128\xd7128 env map that's around 50k texture fetches\nper pixel."),Object(r.b)("p",null,"Fortunately, We can use something called an ",Object(r.b)("strong",{parentName:"p"},"Irradiance map"),". An\nirradiance map is basically the afford mentioned computation...except\nthat it's precomputed and baked into a texture. In practice here is what\nit looks like."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/irradianceMap.png",alt:"irradianceMap"}))),Object(r.b)("p",null,"On the left the original cube map, on the right, the pre computed\nirradiance map."),Object(r.b)("p",null,"So at run time you just have to do one texture fetch in that map with\nthe reflection vector. Pretty cool heh?"),Object(r.b)("p",null,"Except that to pre-compute that map we still have to sample the cube map\nliterally billions of times, and even if it's at design time...it's\npainfully long."),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Spherical Harmonics (SH) to the rescue")),Object(r.b)("p",null,"What's that again? I won't go into explaining them in details (because I\ncan't actually ;-P ), but just know that it's once again some math magic\nwith a big name on it. Here is a post where it's explained with simple\nwords, in terms of what you can use them for."),Object(r.b)("p",null,"To put it simple, SH can help us to compute the irradiance map way\nfaster. This article explains that it all boils down to compute only 9\nspherical harmonics coefficients to efficiently approximate an\nirradiance factor."),Object(r.b)("p",null,"At this point you can even skip the pre computation of the irradiance\nmap, and use those coefficients directly in your shader for each shaded\npixels. That's fast enough to be real time, and use less memory than a\ncube map."),Object(r.b)("p",null,"But still...it's slower than one texture fetch, so I chose to compute\nthe Irradiance map and use it in the shader."),Object(r.b)("p",null,"With this technique I can compute a 128X128 irradiance cube map on the\nCPU in Java in about 200ms. Too slow to be done on each frame, but at\ndesign time that's the blink of an eye."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/DiffuseIBL.png",alt:"DiffuseIBL"}))),Object(r.b)("p",null,"Here is the diffuse effect of indirect lighting using an irradiance cube\nmap"),Object(r.b)("h2",{id:"ibl-specular"},"IBL Specular"),Object(r.b)("p",null,'Indirect diffuse is cool, but we want "shiny"!! Shiny implies specular\nlighting.'),Object(r.b)("p",null,"It's important to understand what we want as a specular reflection. We\nwant it to be very neat when the roughness is low and very blurry when\nit's high."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/Roughness.png",alt:"Roughness"}))),Object(r.b)("p",null,"As roughness increase the reflection gets more blurry."),Object(r.b)("p",null,"To do this, we have to resolve an integral called the ",Object(r.b)("strong",{parentName:"p"},"radiance\nintegral.")),Object(r.b)("p",null,"There is a method to do it quite fast that is called ",Object(r.b)("strong",{parentName:"p"},"importance\nsampling"),". However it requires a lot of samples to get correct results,\nand therefore it's pretty slow."),Object(r.b)("p",null,"As an example, for the previous shot, I was using this method, with 1024\nsamples. It was barely interactive, because it ran at 16 fps on a GTX\n670."),Object(r.b)("h2",{id:"thanks-epic-games"},"Thanks Epic games!"),Object(r.b)("p",null,"Epic games came with a solution to this issue for Unreal Engine 4.\nOthers did too, actually, but Epic games made it public in this paper,\nfrom Brian Karis. I can't thank them enough for this."),Object(r.b)("p",null,"In this\n",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"http://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf"}),"paper"),",\nthey explain how they do it in UE4. They use a method they called the\n",Object(r.b)("strong",{parentName:"p"},"Split Sum Approximation"),". It doesn't make the computation faster, but\nit transforms it so that it can be baked in two prefiltered textures."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"The prefiltered environment map")),Object(r.b)("p",null,"We are going to pre process an env map on the CPU."),Object(r.b)("p",null,"As explained before, we need the reflection to be more blurry as the\nroughness increase. The main idea here is to store different levels of\nroughness in the env map mip maps. The first mip map level will match\nroughness = 0 and the last will match roughness = 1."),Object(r.b)("p",null,"From mip levels to mip levels we're going to convolve (blur) the images\ndepending on the roughness. The more the roughness increase the more\nsamples we're going to use, and the more spread out they will be."),Object(r.b)("p",null,'But that\'s not all, we also want to "bake" the specular BRDF in the map,\nso for each pixel we are going to compute the Cook-Torrentz microfacet\nBRDF (remember last post).'),Object(r.b)("p",null,"But, as we are preprocessing the map, we don't have any information\nabout the shaded surface normal and view direction. So we are going to\nassume they are all the same, and equal to the envVector we'll use to\nfetch pixels from the map. Also we assume that the shading point is\nexactly at the center of the cube map."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/prefilteredEnvMapSampling.png",alt:"prefilteredEnvMapSampling"}))),Object(r.b)("p",null,"This is an approximation again, and it has a cost in quality, but we're\nall for approximation as long as it's perform faster while still looking\ngood, right?"),Object(r.b)("p",null,"Here is what the result looks like"),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/PrefilteredEnvMap.png",alt:"PrefilteredEnvMap"}))),Object(r.b)("p",null,"The prefiltered environment map, with the different mip levels. notice\nhow the blur increases through them."),Object(r.b)("p",null,"So now we can evaluate the first sum of the split sum approximation with\na single texture fetch. We are going to compute the Lod level (the mip\nlevel where to fetch the texel) according to the roughness."),Object(r.b)("p",null,"Note that the image needs to be set up so that textureCube interpolates\nlinearly between mip maps so that if the roughness value is not right on\nthe mip level, it will interpolate between the two closest mip levels."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},"The BRDF integration Map")),Object(r.b)("p",null,"Now we need the second sum of the split sum approximation."),Object(r.b)("p",null,"It's an integration that has two inputs, the ",Object(r.b)("strong",{parentName:"p"},"roughness")," that varies\nfrom 0 to 1, and the dot product between the normal and the light\ndirection (",Object(r.b)("strong",{parentName:"p"},"N.L"),", read N dot L) that also varies from 0 to 1."),Object(r.b)("p",null,"The outputs are a ",Object(r.b)("strong",{parentName:"p"},"scale"),", and a ",Object(r.b)("strong",{parentName:"p"},"bias"),", also varying from 0 to 1."),Object(r.b)("p",null,"So basically we can bake all combinations into a 2D map. roughness and\nN.L will be the texture coordinate. the red channel of the map will be\nthe scale, and the green channel will be the bias. (the blue channel is\nnot used)"),Object(r.b)("p",null,"Here is what it looks like :"),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/integrateBrdf.png",alt:"integrateBrdf"}))),Object(r.b)("p",null,"The nice part is that this map is constant for white light. It does not\ndepends on the environment. So you can bake it once and for all then use\nit as an asset in your shaders."),Object(r.b)("p",null,"Now we have to combine values fetched from these maps to get the\nspecular lighting."),Object(r.b)("p",null,"Here is what indirect specular alone, looks like, with a roughness of\n0.1."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/jme3/advanced/IndirectSpeculra.png",alt:"IndirectSpeculra"}))),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"So in the end :")),Object(r.b)("p",null,"Our indirect lighting pseudo code looks like this :"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"//diffuse\nindirectDiffuse = textureCube(IrradianceMap, refVec)  * diffuseColor\n\n//specular\nlod = getMipLevelFromRoughness(roughness)\nprefilteredColor =  textureCube(PrefilteredEnvMap, refVec, lod)\nenvBRDF = texture2D(BRDFIntegrationMap,vec2(roughness, ndotv)).xy\nindirectSpecular = prefilteredColor * (specularColor * envBRDF.x + envBRDF.y)\n\nindirectLighting = indirectDiffuse + indirectSpecular\n")),Object(r.b)("p",null,"That concludes the post. Quite a lot of information to process. Now you\nshould have an idea of the whole thing. Next time, we are going to go\nunder the hood, and YOU GONNA HAZ CODE!!"),Object(r.b)("h1",{id:"lexical-"},"Lexical :"),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Global Illumination (GI):")," A concept that represent all the lighting\nof a scene that is not coming from a direct light source."),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Image Based Lighting (IBL):")," A technique that uses an image as a\nlight source"),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Irradiance map :")," Precomputed environment map that contains diffuse\nlighting data of the environment."),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Spherical Harmonics (SH):")," ",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://dickyjim.wordpress.com/2013/09/04/spherical-harmonics-for-beginners/"}),"Read\nthis")),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Importance Sampling :")," A math technique to approximate the result of\nan integral."),Object(r.b)("p",null,Object(r.b)("strong",{parentName:"p"},"Split Sum Approximation :")," A way,used in Unreal Engine 4, to\ntransform the specular radiance integral into 2 sums that can be easily\nbaked into prefiltered textures."),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"../../jme3%5Cadvanced%5Cpbr_part1"}),"Physically Based Rendering -- Part\none"))),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"../../jme3/advanced/pbr_part2"}),"Physically Based Rendering -- Part\nTwo")))))}p.isMDXComponent=!0},441:function(e,t,n){"use strict";n.d(t,"a",(function(){return h})),n.d(t,"b",(function(){return m}));var a=n(0),i=n.n(a);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var c=i.a.createContext({}),p=function(e){var t=i.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l({},t,{},e)),n},h=function(e){var t=p(e.components);return i.a.createElement(c.Provider,{value:t},e.children)},b={inlineCode:"code",wrapper:function(e){var t=e.children;return i.a.createElement(i.a.Fragment,{},t)}},u=Object(a.forwardRef)((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,o=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),h=p(n),u=a,m=h["".concat(o,".").concat(u)]||h[u]||b[u]||r;return n?i.a.createElement(m,l({ref:t},c,{components:n})):i.a.createElement(m,l({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var c=2;c<r;c++)o[c]=n[c];return i.a.createElement.apply(null,o)}return i.a.createElement.apply(null,n)}u.displayName="MDXCreateElement"}}]);