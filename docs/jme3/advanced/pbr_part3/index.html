<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="generator" content="Docusaurus v2.0.0-alpha.50">
<script src="/js/dark_default.js"></script>

<title data-react-helmet="true">pbr_part3 | jMonkeyEngine Documentation</title>

<meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:title" content="pbr_part3 | jMonkeyEngine Documentation"><meta data-react-helmet="true" name="description" content="![irradianceMap](/images/jme3/advanced/irradianceMap.png)"><meta data-react-helmet="true" property="og:description" content="![irradianceMap](/images/jme3/advanced/irradianceMap.png)"><meta data-react-helmet="true" property="og:url" content="https://8keep.github.io/wikidemo/docs/jme3/advanced/pbr_part3">

<link data-react-helmet="true" rel="shortcut icon" href="/wikidemoimg/favicon.ico">


<link rel="stylesheet" href="/wikidemostyles.7d008dc0.css">


<link rel="preload" href="/wikidemostyles.08ff7081.js" as="script">

<link rel="preload" href="/wikidemoruntime~main.aab3cf1b.js" as="script">

<link rel="preload" href="/wikidemomain.53cb7c94.js" as="script">

<link rel="preload" href="/wikidemo1.e501629b.js" as="script">

<link rel="preload" href="/wikidemo2.c824d386.js" as="script">

<link rel="preload" href="/wikidemo302.1d1a2997.js" as="script">

<link rel="preload" href="/wikidemo394d525a.30c299b8.js" as="script">

<link rel="preload" href="/wikidemo17896441.d065d5f5.js" as="script">

<link rel="preload" href="/wikidemo313d63e3.dbac1d65.js" as="script">

</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=window.matchMedia("(prefers-color-scheme: dark)"),n=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==n?t(n):e.matches&&t("dark")}()</script>
<div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a aria-current="page" class="navbar__brand active" href="/wikidemo"><img class="navbar__logo" src="/wikidemoimg/iconx128.png" alt="JmonkeyEngine"><strong class="navbar__title"></strong></a><a class="navbar__item navbar__link" href="/wikidemodocs/documentation">Docs</a></div><div class="navbar__items navbar__items--right"><a target="_blank" rel="noopener noreferrer" href="https://github.com/8keep/wikidemo" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_1gtM"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_keGJ moon_1gwN"></span></div><div class="react-toggle-track-x"><span class="toggle_keGJ sun_3CPA"></span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a aria-current="page" class="navbar__brand active" href="/wikidemo"><img class="navbar__logo" src="/wikidemoimg/iconx128.png" alt="JmonkeyEngine"><strong class="navbar__title"></strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/wikidemodocs/documentation">Docs</a></li><li class="menu__list-item"><a target="_blank" rel="noopener noreferrer" href="https://github.com/8keep/wikidemo" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_1kjD"><main class="docMainContainer_FFX1"><div class="padding-vert--lg"><div class="container"><div class="row"><div class="col docItemCol_2GOA"><div class="docItemContainer_2cwg"><article><header><h1 class="docTitle_1vWb">pbr_part3</h1></header><div class="markdown"><p><img src="/images/jme3/advanced/irradianceMap.png" alt="irradianceMap"></p><p><strong>Note</strong> : after several discussions in the team, I realized that some
points were not clear in the &quot;PBR for artists&quot; post. I&#x27;ve made an update
with additional information on how to handle metalness and specular. I
invite you to read it.</p><p><a href="/wikidemo/docs/jme3\advanced\pbr_part1">Physically Based Rendering -- Part
one</a></p><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="image-based-lighting-in-pbr"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#image-based-lighting-in-pbr" title="Direct link to heading">#</a>Image Based Lighting in PBR</h1><p>In <a href="/wikidemo/docs/jme3/advanced/pbr_part2">Physically Based Rendering -- Part
Two</a>, I talked about the basics of
PBR for developers, and explained the different steps of the lighting
process with PBR.</p><p>As said before, PBR does not necessarily imply to have indirect
lighting, But that&#x27;s what makes it look so good.</p><p>Today I&#x27;m gonna focus on a technique called Image Based Lighting (IBL),
that will allow us to cheaply compute this indirect lighting.</p><p>As before you can find at the end of the article a lexical with
definitions of various unusual terms you&#x27;ll come across.</p><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="indirect-lighting-for-pbr-with-image-based-lighting"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#indirect-lighting-for-pbr-with-image-based-lighting" title="Direct link to heading">#</a>Indirect Lighting for PBR with Image Based Lighting.</h1><p>Direct lighting is usually pretty clear for everyone as it uses common
light sources (point light, directional light,...).</p><p>However indirect lighting is not that obvious. First you need to
understand what we want to simulate with indirect light.</p><p>It is often referred as <strong>Global Illumination (or GI)</strong>. This represents
the light bouncing on surrounding objects that is lighting the shaded
surface. There are several techniques to implement global illumination,
but the most common is <strong>Image Based Lighting (IBL)</strong>. It is very often
associated with PBR pipelines.</p><p>So basically, a light source in game is a color, and optionally other
parameters like direction, position, radius, etc... An image has color
informations, and this color can be considered as a light source.</p><p>For global Illumination light is coming from everywhere. So a good way
to simulate GI with IBL is to consider an environment map as a light
source.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="reminder-on-environment-maps-"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#reminder-on-environment-maps-" title="Direct link to heading">#</a>Reminder on environment maps :</h2><p>Most often, in-game environment maps are cube maps.</p><p>How do we fetch a pixel from an environment map? We need a vector. Often
called the reflect vector (refVec), because thats the reflection vector
of the view direction on the shaded surface.</p><p>A picture worth thousand words</p><p><img src="/images/jme3/advanced/Cube_mapped_reflection_example.jpg" alt="Cube_mapped_reflection_example"></p><p>from wikipedia : TopherTH at the English language Wikipedia [GFDL
(<a href="http://www.gnu.org/copyleft/fdl.html">http://www.gnu.org/copyleft/fdl.html</a>), GFDL
(<a href="http://www.gnu.org/copyleft/fdl.html">http://www.gnu.org/copyleft/fdl.html</a>) or CC-BY-SA-3.0
(<a href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>)], via Wikimedia
Commons Here the reflected Ray is our reflection vector.</p><p>Here the reflected Ray is our reflection vector.</p><p>Unfortunately we can&#x27;t take each pixel of the env map and compute light
as if it was a direct light source and hope for the best.</p><p>There&#x27;s crazy math around that topic, and to be honest I didn&#x27;t get all
of it myself. So instead of explaining difficult math equations that may
be confusing, I&#x27;m gonna go straight to the point : How are we going to
compute lighting from the environment map?</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="ibl-diffuse"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#ibl-diffuse" title="Direct link to heading">#</a>IBL Diffuse</h2><p>First we need to compute Diffuse factor from the environment map.
Remember our diffuse BRDF from last post? <strong>Lambert</strong>.</p><p>To simplify, Lambert diffuse BRDF, as it&#x27;s used in game, is the light
color multiplied by a visibility factor.</p><p>This visibility factor is a function of the normal of the shaded
geometry and the light direction.</p><p>Let&#x27;s say you have a direct light source lighting the front side of a
geometry. The back side of this geometry is in the dark. Meaning the
front side visibility factor is 1 and the back side visibility factor is
0.</p><p>For indirect lighting, we can ditch out this visibility factor because
the light is coming from everywhere. So all of this simplifies in
Diffuse factor = light color.</p><p>But what&#x27;s the light color for a given point?</p><p>Technically, every pixel in the environment map is a light source, so a
shaded point is lighten by a vast amount of pixels.</p><p><img src="/images/jme3/advanced/irradiance.png" alt="irradiance"></p><p>In this picture the orange area represent the light rays coming from the
cube map to the shaded pixel, that we have to consider to properly
compute the light color. So the idea would be, for each shaded pixel, to
fetch all that texels and combine the colors.</p><p>As you can image that&#x27;s not practical for a real time rendering
pipeline. Even with a 128×128 env map that&#x27;s around 50k texture fetches
per pixel.</p><p>Fortunately, We can use something called an <strong>Irradiance map</strong>. An
irradiance map is basically the afford mentioned computation...except
that it&#x27;s precomputed and baked into a texture. In practice here is what
it looks like.</p><p><img src="/images/jme3/advanced/irradianceMap.png" alt="irradianceMap"></p><p>On the left the original cube map, on the right, the pre computed
irradiance map.</p><p>So at run time you just have to do one texture fetch in that map with
the reflection vector. Pretty cool heh?</p><p>Except that to pre-compute that map we still have to sample the cube map
literally billions of times, and even if it&#x27;s at design time...it&#x27;s
painfully long.</p><p><strong>Spherical Harmonics (SH) to the rescue</strong></p><p>What&#x27;s that again? I won&#x27;t go into explaining them in details (because I
can&#x27;t actually ;-P ), but just know that it&#x27;s once again some math magic
with a big name on it. Here is a post where it&#x27;s explained with simple
words, in terms of what you can use them for.</p><p>To put it simple, SH can help us to compute the irradiance map way
faster. This article explains that it all boils down to compute only 9
spherical harmonics coefficients to efficiently approximate an
irradiance factor.</p><p>At this point you can even skip the pre computation of the irradiance
map, and use those coefficients directly in your shader for each shaded
pixels. That&#x27;s fast enough to be real time, and use less memory than a
cube map.</p><p>But still...it&#x27;s slower than one texture fetch, so I chose to compute
the Irradiance map and use it in the shader.</p><p>With this technique I can compute a 128X128 irradiance cube map on the
CPU in Java in about 200ms. Too slow to be done on each frame, but at
design time that&#x27;s the blink of an eye.</p><p><img src="/images/jme3/advanced/DiffuseIBL.png" alt="DiffuseIBL"></p><p>Here is the diffuse effect of indirect lighting using an irradiance cube
map</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="ibl-specular"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#ibl-specular" title="Direct link to heading">#</a>IBL Specular</h2><p>Indirect diffuse is cool, but we want &quot;shiny&quot;!! Shiny implies specular
lighting.</p><p>It&#x27;s important to understand what we want as a specular reflection. We
want it to be very neat when the roughness is low and very blurry when
it&#x27;s high.</p><p><img src="/images/jme3/advanced/Roughness.png" alt="Roughness"></p><p>As roughness increase the reflection gets more blurry.</p><p>To do this, we have to resolve an integral called the <strong>radiance
integral.</strong></p><p>There is a method to do it quite fast that is called <strong>importance
sampling</strong>. However it requires a lot of samples to get correct results,
and therefore it&#x27;s pretty slow.</p><p>As an example, for the previous shot, I was using this method, with 1024
samples. It was barely interactive, because it ran at 16 fps on a GTX
670.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="thanks-epic-games"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#thanks-epic-games" title="Direct link to heading">#</a>Thanks Epic games!</h2><p>Epic games came with a solution to this issue for Unreal Engine 4.
Others did too, actually, but Epic games made it public in this paper,
from Brian Karis. I can&#x27;t thank them enough for this.</p><p>In this
<a href="http://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf">paper</a>,
they explain how they do it in UE4. They use a method they called the
<strong>Split Sum Approximation</strong>. It doesn&#x27;t make the computation faster, but
it transforms it so that it can be baked in two prefiltered textures.</p><ul><li>The prefiltered environment map</li></ul><p>We are going to pre process an env map on the CPU.</p><p>As explained before, we need the reflection to be more blurry as the
roughness increase. The main idea here is to store different levels of
roughness in the env map mip maps. The first mip map level will match
roughness = 0 and the last will match roughness = 1.</p><p>From mip levels to mip levels we&#x27;re going to convolve (blur) the images
depending on the roughness. The more the roughness increase the more
samples we&#x27;re going to use, and the more spread out they will be.</p><p>But that&#x27;s not all, we also want to &quot;bake&quot; the specular BRDF in the map,
so for each pixel we are going to compute the Cook-Torrentz microfacet
BRDF (remember last post).</p><p>But, as we are preprocessing the map, we don&#x27;t have any information
about the shaded surface normal and view direction. So we are going to
assume they are all the same, and equal to the envVector we&#x27;ll use to
fetch pixels from the map. Also we assume that the shading point is
exactly at the center of the cube map.</p><p><img src="/images/jme3/advanced/prefilteredEnvMapSampling.png" alt="prefilteredEnvMapSampling"></p><p>This is an approximation again, and it has a cost in quality, but we&#x27;re
all for approximation as long as it&#x27;s perform faster while still looking
good, right?</p><p>Here is what the result looks like</p><p><img src="/images/jme3/advanced/PrefilteredEnvMap.png" alt="PrefilteredEnvMap"></p><p>The prefiltered environment map, with the different mip levels. notice
how the blur increases through them.</p><p>So now we can evaluate the first sum of the split sum approximation with
a single texture fetch. We are going to compute the Lod level (the mip
level where to fetch the texel) according to the roughness.</p><p>Note that the image needs to be set up so that textureCube interpolates
linearly between mip maps so that if the roughness value is not right on
the mip level, it will interpolate between the two closest mip levels.</p><ul><li>The BRDF integration Map</li></ul><p>Now we need the second sum of the split sum approximation.</p><p>It&#x27;s an integration that has two inputs, the <strong>roughness</strong> that varies
from 0 to 1, and the dot product between the normal and the light
direction (<strong>N.L</strong>, read N dot L) that also varies from 0 to 1.</p><p>The outputs are a <strong>scale</strong>, and a <strong>bias</strong>, also varying from 0 to 1.</p><p>So basically we can bake all combinations into a 2D map. roughness and
N.L will be the texture coordinate. the red channel of the map will be
the scale, and the green channel will be the bias. (the blue channel is
not used)</p><p>Here is what it looks like :</p><p><img src="/images/jme3/advanced/integrateBrdf.png" alt="integrateBrdf"></p><p>The nice part is that this map is constant for white light. It does not
depends on the environment. So you can bake it once and for all then use
it as an asset in your shaders.</p><p>Now we have to combine values fetched from these maps to get the
specular lighting.</p><p>Here is what indirect specular alone, looks like, with a roughness of
0.1.</p><p><img src="/images/jme3/advanced/IndirectSpeculra.png" alt="IndirectSpeculra"></p><p><strong>So in the end :</strong></p><p>Our indirect lighting pseudo code looks like this :</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain">//diffuse</span></div><div class="token-line" style="color:#393A34"><span class="token plain">indirectDiffuse = textureCube(IrradianceMap, refVec)  * diffuseColor</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">//specular</span></div><div class="token-line" style="color:#393A34"><span class="token plain">lod = getMipLevelFromRoughness(roughness)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">prefilteredColor =  textureCube(PrefilteredEnvMap, refVec, lod)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">envBRDF = texture2D(BRDFIntegrationMap,vec2(roughness, ndotv)).xy</span></div><div class="token-line" style="color:#393A34"><span class="token plain">indirectSpecular = prefilteredColor * (specularColor * envBRDF.x + envBRDF.y)</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">indirectLighting = indirectDiffuse + indirectSpecular</span></div></div></div></div></div><p>That concludes the post. Quite a lot of information to process. Now you
should have an idea of the whole thing. Next time, we are going to go
under the hood, and YOU GONNA HAZ CODE!!</p><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="lexical-"></a><a aria-hidden="true" tabindex="-1" class="hash-link" href="#lexical-" title="Direct link to heading">#</a>Lexical :</h1><p><strong>Global Illumination (GI):</strong> A concept that represent all the lighting
of a scene that is not coming from a direct light source.</p><p><strong>Image Based Lighting (IBL):</strong> A technique that uses an image as a
light source</p><p><strong>Irradiance map :</strong> Precomputed environment map that contains diffuse
lighting data of the environment.</p><p><strong>Spherical Harmonics (SH):</strong> <a href="https://dickyjim.wordpress.com/2013/09/04/spherical-harmonics-for-beginners/">Read
this</a></p><p><strong>Importance Sampling :</strong> A math technique to approximate the result of
an integral.</p><p><strong>Split Sum Approximation :</strong> A way,used in Unreal Engine 4, to
transform the specular radiance integral into 2 sums that can be easily
baked into prefiltered textures.</p><ul><li><p><a href="/wikidemo/docs/jme3\advanced\pbr_part1">Physically Based Rendering -- Part
one</a></p></li><li><p><a href="/wikidemo/docs/jme3/advanced/pbr_part2">Physically Based Rendering -- Part
Two</a></p></li></ul></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/8keep/wikidemo/edit/master/docs/jme3/advanced/pbr_part3.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_TbNY"><ul class="contents contents__left-border"><li><a href="#reminder-on-environment-maps-" class="contents__link">Reminder on environment maps :</a></li><li><a href="#ibl-diffuse" class="contents__link">IBL Diffuse</a></li><li><a href="#ibl-specular" class="contents__link">IBL Specular</a></li><li><a href="#thanks-epic-games" class="contents__link">Thanks Epic games!</a></li></ul></div></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="text--center"><div>Copyright © 2020 jMonkeyEngine.</div></div></div></footer>
</div>

<script src="/wikidemostyles.08ff7081.js"></script>

<script src="/wikidemoruntime~main.aab3cf1b.js"></script>

<script src="/wikidemomain.53cb7c94.js"></script>

<script src="/wikidemo1.e501629b.js"></script>

<script src="/wikidemo2.c824d386.js"></script>

<script src="/wikidemo302.1d1a2997.js"></script>

<script src="/wikidemo394d525a.30c299b8.js"></script>

<script src="/wikidemo17896441.d065d5f5.js"></script>

<script src="/wikidemo313d63e3.dbac1d65.js"></script>


</body>
</html>